{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9b4bbe8",
   "metadata": {},
   "source": [
    "# NLP Project : Emotion Detection in Dialogues\n",
    "## I - Collecting Data\n",
    "## II - Baseline Model (Bert Encoding)\n",
    "## III - Bidirectionnal LTSM model\n",
    "## IV - Adding Self-Attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1077658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from nltk.tokenize import TreebankWordTokenizer, TweetTokenizer\n",
    "import pandas as pd\n",
    "from termcolor import colored\n",
    "from collections import Counter\n",
    "from torchtext.vocab import GloVe, vocab, FastText\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from tqdm.auto import tqdm\n",
    "tok = TweetTokenizer()\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, RocCurveDisplay \n",
    "import matplotlib.pyplot as plt\n",
    "import datasets\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from transformers import get_scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfe87ad",
   "metadata": {},
   "source": [
    "## I - Collecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3aed0b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset daily_dialog (/Users/mathieugarrouty/.cache/huggingface/datasets/daily_dialog/default/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a331e4b2aca546b483014b61deb5d404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/87170 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8069 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7740 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dailydialog = load_dataset('daily_dialog')\n",
    "dico=dict()\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    L=[]\n",
    "    for el in dailydialog[split] :\n",
    "        for i in range(len(el[\"dialog\"])) :\n",
    "            L.append({'text': el[\"dialog\"][i], \"label\" : el[\"act\"][i]})\n",
    "    dico[split]=datasets.Dataset.from_list(L)\n",
    "    \n",
    "dataset = datasets.DatasetDict()\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    dataset[split]=dico[split]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\", use_fast=True)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(200))\n",
    "val_dataset = tokenized_datasets[\"validation\"].shuffle(seed=42).select(range(200))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=8)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6f36fde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b209bb226b7741a88904d91d6a2fcb11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Placeholder storage has not been allocated on MPS device!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m     21\u001b[0m     batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m---> 22\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m     24\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1563\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1555\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1560\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1561\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1563\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1570\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1573\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1575\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1577\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1012\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1012\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1019\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m   1020\u001b[0m     embedding_output,\n\u001b[1;32m   1021\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1029\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1030\u001b[0m )\n\u001b[1;32m   1031\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:230\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    227\u001b[0m         token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m token_type_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings(token_type_ids)\n\u001b[1;32m    233\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m token_type_embeddings\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/sparse.py:160\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Placeholder storage has not been allocated on MPS device!"
     ]
    }
   ],
   "source": [
    "args.update({'max_eps': 5, 'lr': 0.0001, 'device': \"mps\", 'num_class': 5})\n",
    "\n",
    "# This model is equal to BERT + a linear layer for classification. In our custom model we designed a FastText + a hidden layer and linear layer for classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", num_labels=args[\"num_class\"])\n",
    "optimizer = AdamW(model.parameters(), lr=args[\"lr\"])\n",
    "\n",
    "device=args[\"device\"]\n",
    "num_epochs = args[\"max_eps\"]\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95814ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ee65b2ed774fca87b3a0daacbcd6f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "evaluating:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.675}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric(\"accuracy\")\n",
    "model.eval()\n",
    "preds, trues = [], []\n",
    "for i, batch in tqdm(enumerate(eval_dataloader), desc=\"evaluating\", total=eval_dataloader.__len__()):\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "    _, tag_seq  = torch.max(logits, 1)\n",
    "    preds.extend(tag_seq.cpu().detach().tolist())\n",
    "    trues.extend(batch['labels'].cpu().detach().tolist())\n",
    "\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "203130f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      inform       0.64      0.95      0.76       100\n",
      "    question       0.78      0.78      0.78        51\n",
      "   directive       0.00      0.00      0.00        36\n",
      "  commissive       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.68       200\n",
      "   macro avg       0.36      0.43      0.39       200\n",
      "weighted avg       0.52      0.68      0.58       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mathieugarrouty/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mathieugarrouty/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mathieugarrouty/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "names = [ 'inform', 'question', 'directive', 'commissive']\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, RocCurveDisplay \n",
    "print(classification_report(np.array(trues), np.array(preds), target_names=names, labels=[1, 2, 3, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7161fd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true 3 predicted 1 \u001b[31mMistake\u001b[0m\n",
      "true 1 predicted 1 \u001b[32mCorrect\u001b[0m\n",
      "true 1 predicted 1 \u001b[32mCorrect\u001b[0m\n",
      "true 1 predicted 1 \u001b[32mCorrect\u001b[0m\n",
      "true 1 predicted 1 \u001b[32mCorrect\u001b[0m\n",
      "true 3 predicted 1 \u001b[31mMistake\u001b[0m\n",
      "true 1 predicted 1 \u001b[32mCorrect\u001b[0m\n",
      "true 1 predicted 1 \u001b[32mCorrect\u001b[0m\n",
      "true 1 predicted 1 \u001b[32mCorrect\u001b[0m\n",
      "true 2 predicted 1 \u001b[31mMistake\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for t, p in zip(trues[:10], preds[:10]):\n",
    "  correct = colored('Correct', 'green') if t == p else colored('Mistake', 'red')\n",
    "  print('true', t, 'predicted', p, correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f57272a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset daily_dialog (/Users/mathieugarrouty/.cache/huggingface/datasets/daily_dialog/default/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a763f776d20e4d0e9cd7dfef959221de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/mathieugarrouty/.cache/huggingface/datasets/daily_dialog/default/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd/cache-21a876f7e95bccd1.arrow\n",
      "Loading cached processed dataset at /Users/mathieugarrouty/.cache/huggingface/datasets/daily_dialog/default/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd/cache-0b0464fc3c4b6025.arrow\n",
      "Loading cached processed dataset at /Users/mathieugarrouty/.cache/huggingface/datasets/daily_dialog/default/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd/cache-6c8d81b726aec4fc.arrow\n"
     ]
    }
   ],
   "source": [
    "dailydialog = load_dataset('daily_dialog')\n",
    "\n",
    "pretrained_vectors = FastText(language='en')\n",
    "pretrained_vocab = vocab(pretrained_vectors.stoi)\n",
    "unk_token = \"<unk>\"\n",
    "unk_index = 0\n",
    "pad_token = '<pad>'\n",
    "pad_index = 1\n",
    "pretrained_vocab.insert_token(\"<unk>\",unk_index)\n",
    "pretrained_vocab.insert_token(\"<pad>\", pad_index)\n",
    "#this is necessary otherwise it will throw runtime error if OOV token is queried \n",
    "pretrained_vocab.set_default_index(unk_index)\n",
    "pretrained_embeddings = pretrained_vectors.vectors\n",
    "pretrained_embeddings = torch.cat((torch.zeros(1,pretrained_embeddings.shape[1]),pretrained_embeddings))\n",
    "pretrained_embeddings.size()\n",
    "\n",
    "def tokenize_pad_numericalize_dialog(entry, vocab_stoi, max_length=20):\n",
    "  ''' message level '''\n",
    "  dialog = [ [ vocab_stoi[token] if token in vocab_stoi else vocab_stoi['<unk>'] for token in tok.tokenize(e.lower()) ] \n",
    "          for e in entry ]\n",
    "  padded_dialog = list()\n",
    "  for d in dialog:\n",
    "    if len(d) < max_length:    padded_dialog.append( d + [ vocab_stoi['<pad>'] for i in range(len(d), max_length) ] )\n",
    "    elif len(d) > max_length:  padded_dialog.append(d[:max_length])\n",
    "    else:                      padded_dialog.append(d) \n",
    "  return padded_dialog\n",
    "\n",
    "def tokenize_all_dialog(entries, vocab_stoi, max_message_length=20, max_dialog_length=12):\n",
    "  ''' dialog level '''\n",
    "  pad_message = [ vocab_stoi['<pad>'] ]\n",
    "  pad_label = [0] # because 0 means dummy in dialog acts mapping\n",
    "  res_dialog, res_labels = [], []\n",
    "\n",
    "  for entry in entries['dialog']:\n",
    "    text  = tokenize_pad_numericalize_dialog(entry, vocab_stoi)\n",
    "    if len(text) < max_dialog_length:    text = text + [ [vocab_stoi['<pad>']] * max_message_length for i in range(len(text), max_dialog_length)]   # pad_message * (max_dialog_length - len(text))\n",
    "    elif len(text) > max_dialog_length:  text = text[-max_dialog_length:] # keeps the last n messages\n",
    "    res_dialog.append(text)\n",
    "\n",
    "  for labels in entries['act']:\n",
    "    if len(labels) < max_dialog_length:   labels = labels + [ 0 for i in range(len(labels), max_dialog_length) ]          # pad_label * (max_dialog_length - len(labels))\n",
    "    elif len(labels) > max_dialog_length: labels = labels[-max_dialog_length:]\n",
    "    res_labels.append(labels)\n",
    "\n",
    "  res = {'text': res_dialog, 'label': res_labels}\n",
    "  return res\n",
    "\n",
    "vocab_stoi = pretrained_vocab.get_stoi()\n",
    "\n",
    "for split in ['train', 'validation', 'test']:\n",
    "  dailydialog[split] = dailydialog[split].map(lambda e: tokenize_all_dialog(e, vocab_stoi), batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902e2d74",
   "metadata": {},
   "source": [
    "## II - Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4435cca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare dataloader\n",
    "class BDataset(Dataset):\n",
    "    def __init__(self, data, args):\n",
    "      # args is a dict, a nice way to share the global arguments (even accross multiple files)\n",
    "      self.args = args\n",
    "      self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "      # idx is the row index\n",
    "      # text and labels should be numpy arrays\n",
    "      item = {\n",
    "          \"text\": np.array(self.data[idx]['text']),\n",
    "          \"label\": np.array(self.data[idx]['label'])\n",
    "      }\n",
    "      return item\n",
    "    \n",
    "args = {'bsize': 64}\n",
    "\n",
    "#We define new datasets \n",
    "dico=dict()\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    L=[]\n",
    "    for el in dailydialog[split] :\n",
    "        for i in range(len(el[\"text\"])) :\n",
    "            L.append({'text': el[\"text\"][i], \"label\" : el[\"label\"][i]})\n",
    "    dico[split]=datasets.Dataset.from_list(L)\n",
    "    \n",
    "\n",
    "train_loader = DataLoader(BDataset(dico['train'],args), batch_size=args[\"bsize\"] , shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(BDataset(dico['validation'],args), batch_size=args[\"bsize\"] , shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(BDataset(dico['test'],args), batch_size=args[\"bsize\"] , shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "2f0320ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 4598, 1: 3417, 2: 2066, 3: 1216, 4: 703})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(dico['test']['label']) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b9ab5f",
   "metadata": {},
   "source": [
    "### II.2 Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "dbbd6b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, pretrained_vectors=None):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "        \"\"\"\n",
    "        super(BaselineModel, self).__init__()\n",
    "        self.ebd = torch.nn.Embedding.from_pretrained(pretrained_vectors, freeze=True)\n",
    "        self.hidden_linear_layer = torch.nn.Linear(hidden_dim, hidden_dim, bias=True)\n",
    "        self.classification_layer = torch.nn.Linear(hidden_dim, output_dim, bias=True)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data and we must return\n",
    "        a Tensor of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Tensors.\n",
    "        \"\"\"\n",
    "        x  = self.ebd(x)\n",
    "        x = torch.mean(x,1)\n",
    "        h  = torch.relu(self.hidden_linear_layer(x))\n",
    "        h  = self.classification_layer(h)\n",
    "        \n",
    "        # apply the softmax layer\n",
    "        logits = self.softmax(h)\n",
    "        return logits \n",
    "\n",
    "\n",
    "def train(model, optimizer, ep, args):\n",
    "  # set the model into a training mode : the model's weights and parameters WILL BE updated!\n",
    "  model.train()\n",
    "  # initialize empty lists for losses and accuracies\n",
    "  loss_it, acc_it = list(), list()\n",
    "\n",
    "  # start the loop over all the training batches. This means one full epoch.\n",
    "  for it, batch in tqdm(enumerate(train_loader), desc=\"Epoch %s:\" % (ep), total=train_loader.__len__()):\n",
    "    \n",
    "    batch = {'text': batch['text'].to(device), 'label': batch['label'].to(device)}\n",
    "\n",
    "    # put parameters of the model and the optimizer to zero before doing another iteration. this prevents the gradient accumulation through batches\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # apply the model on the batch\n",
    "    logits = model(batch['text'])\n",
    "\n",
    "    # # # to deal with unbalanced data in the batch, we calculate the weights according to their inverse frequency\n",
    "    b_counter = Counter(batch['label'].detach().cpu().tolist())\n",
    "    b_weights = torch.tensor( [ sum(batch['label'].detach().cpu().tolist()) / b_counter[label] if b_counter[label] > 0 else 0 for label in list(range(args['num_class'])) ] )\n",
    "    b_weights = b_weights.to(device)\n",
    "\n",
    "    # we choose the CrossEntropyLoss, suitable for multiclass classification\n",
    "    loss_function = nn.CrossEntropyLoss(weight=b_weights)\n",
    "    # loss_function = nn.CrossEntropyLoss()\n",
    "    loss = loss_function(logits, batch['label'])\n",
    "\n",
    "    # compute backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "    # indicate to the optimizer we've done a step\n",
    "    optimizer.step()\n",
    "\n",
    "    # append the value of the loss for the current iteration (it). .item() retrieve the nuclear value as a int/long\n",
    "    loss_it.append(loss.item())\n",
    "\n",
    "    # get the predicted tags using the maximum probability from the softmax\n",
    "    _, tag_seq  = torch.max(logits, 1)\n",
    "    \n",
    "    # Those 3 lines compute the accuracy and then append it the same way as the loss above\n",
    "    correct = (tag_seq.flatten() == batch['label'].flatten()).float().sum()\n",
    "    acc = correct / batch['label'].flatten().size(0)\n",
    "    acc_it.append(acc.item())\n",
    "\n",
    "  # simple averages of losses and accuracies for this epoch\n",
    "  loss_it_avg = sum(loss_it)/len(loss_it)\n",
    "  acc_it_avg = sum(acc_it)/len(acc_it)\n",
    "  \n",
    "  # print useful information about the training progress and scores on this training set's full pass (i.e. 1 epoch)\n",
    "  print(\"Epoch %s/%s : %s : (%s %s) (%s %s)\" % (colored(str(ep), 'blue'),args['max_eps'] , colored('Training', 'blue'), colored('loss', 'cyan'), sum(loss_it)/len(loss_it), colored('acc', 'cyan'), sum(acc_it) / len(acc_it)))\n",
    "\n",
    "    \n",
    "def inference(target, loader, model):\n",
    "  \"\"\"\n",
    "    Args:\n",
    "      target (str): modify the display, usually either 'validation' or 'test'\n",
    "  \"\"\"\n",
    "\n",
    "  # set the model into a evaluation mode : the model's weights and parameters will NOT be updated!\n",
    "  model.eval()\n",
    "\n",
    "  # intialize empty list to populate later on\n",
    "  loss_it, acc_it, f1_it = list(), list(), list()\n",
    "  # preds = predicted values ; trues = true values .... obviously~\n",
    "  preds, trues = list(), list()\n",
    "\n",
    "  # loop over the loader batches\n",
    "  for it, batch in tqdm(enumerate(loader), desc=\"%s:\" % (target), total=loader.__len__()):\n",
    "    # set an environnement without any gradient. So the tensor gradients are not considered \n",
    "    # (saves a lot of computation and memory, this is one of the many things that makes predicting far less costly than training)\n",
    "    with torch.no_grad():\n",
    "\n",
    "      # put the batch to the correct device\n",
    "        batch = {'text': batch['text'].to(device), 'label': batch['label'].to(device)}\n",
    "\n",
    "      # apply the model\n",
    "        logits = model(batch['text'])\n",
    "\n",
    "        loss_function = nn.CrossEntropyLoss()\n",
    "        loss = loss_function(logits, batch['label'])\n",
    "\n",
    "      # no need to backward() and other training stuff. Directly store the loss in the list\n",
    "        loss_it.append(loss.item())\n",
    "\n",
    "      # get the predicted tags using the maximum probability from the softmax\n",
    "        _, tag_seq  = torch.max(logits, 1)\n",
    "      \n",
    "      # compute the accuracy and store it\n",
    "        correct = (tag_seq.flatten() == batch['label'].flatten()).float().sum()\n",
    "        acc = correct / batch['label'].flatten().size(0)\n",
    "        acc_it.append(acc.item())\n",
    "\n",
    "      # extend the predictions and true labels lists so we can compare them later on\n",
    "      # note how we first ensure the tensor are on cpu (.cpu()), then we detach() the gradient from the tensor, before transforming it to a simple python list (.tolist())\n",
    "        preds.extend(tag_seq.cpu().detach().tolist())\n",
    "        trues.extend(batch['label'].cpu().detach().tolist())\n",
    "\n",
    "  # compute the average loss and accuracy accross the iterations (batches)\n",
    "    loss_it_avg = sum(loss_it)/len(loss_it)\n",
    "    acc_it_avg = sum(acc_it)/len(acc_it)\n",
    "  \n",
    "  # print useful information. Important during training as we want to know the performance over the validation set after each epoch\n",
    "    print(\"%s : (%s %s) (%s %s)\" % ( colored(target, 'blue'), colored('loss', 'cyan'), sum(loss_it)/len(loss_it), colored('acc', 'cyan'), sum(acc_it) / len(acc_it)))\n",
    "\n",
    "  # return the true and predicted values with the losses and accuracies\n",
    "    return trues, preds, loss_it_avg, acc_it_avg, loss_it, acc_it\n",
    "\n",
    "def run_epochs(model, args):\n",
    "\n",
    "  optimizer = optim.Adam(model.parameters(), lr = args['lr'])\n",
    "\n",
    "  val_ep_losses = list()\n",
    "  # iterate over the number of max epochs set in the arguments\n",
    "  for ep in range(args['max_eps']):\n",
    "    # train the model using our defined function\n",
    "    train(model, optimizer, ep, args)\n",
    "    # apply the model for inference using our defined function\n",
    "    trues, preds, val_loss_it_avg, val_acc_it_avg, val_loss_it, val_acc_it = inference(\"validation\", val_loader, model)\n",
    "    # append the validation losses (good losses should normally go down)\n",
    "    val_ep_losses.append(val_loss_it_avg)\n",
    "\n",
    "  # return the list of epoch validation losses in order to use it later to create a plot\n",
    "  return val_ep_losses\n",
    "\n",
    "sizes = next(iter(train_loader))['text'].size()\n",
    "batchsize = sizes[0]\n",
    "inputdim  = sizes[1]\n",
    "hiddendim = 300 # dimension of the pretrained vector\n",
    "outputdim = 5\n",
    "device=\"cpu\"\n",
    "args.update({'max_eps': 5, 'lr': 0.0001, 'device': device, 'num_class': 5})\n",
    "baseline_model = BaselineModel(inputdim, hiddendim, outputdim, pretrained_vectors=pretrained_vectors.vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a5f8ff",
   "metadata": {},
   "source": [
    "### II.3 Running Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b2e66ecd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss_list_val \u001b[38;5;241m=\u001b[39m \u001b[43mrun_epochs\u001b[49m(baseline_model, args)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'run_epochs' is not defined"
     ]
    }
   ],
   "source": [
    "loss_list_val = run_epochs(baseline_model, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba33efa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec31b56d",
   "metadata": {},
   "source": [
    "### II.4 Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "40a5fb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss(loss_list):\n",
    "  '''\n",
    "  this function creates a plot. a simple curve showing the different values at each steps.\n",
    "  Here we use it to plot the loss so we named it plot_loss, but the same function with different titles could be used to plot accuracies\n",
    "  or other metrics for instance.\n",
    "  \n",
    "  Args:\n",
    "    loss_list (list of floats): list of numerical values\n",
    "  '''\n",
    "  plt.plot(range(len(loss_list)), loss_list)\n",
    "  plt.xlabel('epochs')\n",
    "  # in our model we use Softmax then NLLLoss which means Cross Entropy loss\n",
    "  plt.ylabel('Cross Entropy')\n",
    "  # in our training loop we used an Adam optimizer so we indicate it there\n",
    "  plt.title('lr: {}, optim_alg:{}'.format(args['lr'], 'Adam'))\n",
    "  # let's directly show the plot when calling this function\n",
    "  plt.show()\n",
    "\n",
    "plot_loss(loss_list_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "371cec9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f2f4db3e034beab37f67462ad2e3f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test::   0%|          | 0/187 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mtest\u001b[0m : (\u001b[36mloss\u001b[0m 1.6063250303268433) (\u001b[36macc\u001b[0m 0.40625)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      inform       0.33      0.14      0.20        14\n",
      "    question       0.00      0.00      0.00        15\n",
      "   directive       0.00      0.00      0.00         7\n",
      "  commissive       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.33      0.05      0.09        40\n",
      "   macro avg       0.08      0.04      0.05        40\n",
      "weighted avg       0.12      0.05      0.07        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5_/_p49xztn5cd1d185x6nk48g00000gn/T/ipykernel_17622/2297952344.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  logits = self.softmax(h)\n",
      "/Users/mathieugarrouty/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mathieugarrouty/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mathieugarrouty/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<zip at 0x2af152a80>"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truesb, predsb, loss_it_avgb, acc_it_avgb, loss_itb, acc_itb = inference(\"test\", test_loader, baseline_model)\n",
    "names = [ 'inform', 'question', 'directive', 'commissive']\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, RocCurveDisplay \n",
    "print(classification_report(np.array(truesb), np.array(predsb), target_names=names, labels=[1, 2, 3, 4]))\n",
    "\n",
    "zip(truesb,predsb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "d2196cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n"
     ]
    }
   ],
   "source": [
    "total=0\n",
    "good=0\n",
    "for t, p in zip(truesb, predsb):\n",
    "    if t != 0 :\n",
    "        total+=1\n",
    "        if t==p :\n",
    "            good+=1\n",
    "print(good/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a36b38",
   "metadata": {},
   "source": [
    "### III - Bidirectionnal LTSM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "6a70f31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class DialogActDataset(Dataset):\n",
    "    def __init__(self, data, args):\n",
    "      self.args = args\n",
    "      self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "      item = {\n",
    "          \"text\": np.array(self.data[idx]['text']),\n",
    "          \"label\": np.array(self.data[idx]['label'])\n",
    "      }\n",
    "      return item\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "args = {'bsize': 64}\n",
    "train_loader = DataLoader(DialogActDataset(dailydialog['train'], args), batch_size=args['bsize'], num_workers=0, shuffle=True, drop_last=True)\n",
    "val_loader   = DataLoader(DialogActDataset(dailydialog['validation'], args), batch_size=args['bsize'], num_workers=0, shuffle=True, drop_last=True)\n",
    "test_loader  = DataLoader(DialogActDataset(dailydialog['test'], args), batch_size=args['bsize'], num_workers=0, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "841f689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAvgConvEBD(nn.Module):\n",
    "    '''\n",
    "        An aggregation method that encodes every document by its average word\n",
    "        embeddings.\n",
    "    '''\n",
    "    def __init__(self, ebd, args, avg_global=False):\n",
    "        super(SimpleAvgConvEBD, self).__init__()\n",
    "\n",
    "        # self.ebd = ebd\n",
    "        self.ebd = torch.nn.Embedding.from_pretrained(pretrained_vectors.vectors, freeze=True)\n",
    "\n",
    "        self.avg_global = avg_global\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        '''\n",
    "            @param data dictionary\n",
    "                @key text: batch_size * max_text_len\n",
    "            @return output: batch_size * embedding_dim\n",
    "        '''\n",
    "        ebd = self.ebd(data)\n",
    "\n",
    "        # count length excluding <pad> and <unk>.\n",
    "        is_zero = (torch.sum(torch.abs(ebd), dim=3) > 1e-8).float() \n",
    "        soft_len = torch.sum(is_zero, dim=2, keepdim=True)\n",
    "\n",
    "        soft_len[soft_len < 1] = 1\n",
    "\n",
    "        # # don't need to mask out the <pad> tokens, as the embeddings are zero\n",
    "        ebd = torch.sum(ebd, dim=2) # dim = 2\n",
    "        ebd = ebd / soft_len\n",
    "\n",
    "        # avg_global allows two usages for this model\n",
    "        if self.avg_global:\n",
    "            ebd = torch.mean(ebd, 2)\n",
    "        return ebd\n",
    "    \n",
    "import torch\n",
    "# this import contains multiple CLASSES to use (hence you need to instanciate it). Usually different layer types\n",
    "import torch.nn as nn\n",
    "# this import contains multiple FUNCTIONS to use (hence no need to instanciate it)\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# create the class by inheriting the PyTorch Module\n",
    "class BiLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained_embeddings, num_class, args, dimension=300, freeze_embeddings = False):\n",
    "        '''\n",
    "        construtor of the class (function automatically used when creating a new instance of this class)\n",
    "        '''\n",
    "        super(BiLSTM, self).__init__()\n",
    "\n",
    "        # put args as a class variable\n",
    "        self.args = args\n",
    "        # create the embedding layer from the pretrained vectors\n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_vectors.vectors, freeze=freeze_embeddings)\n",
    "\n",
    "        # instanciate the SimpleAvgConvEBD class, dedicate to average the utterances\n",
    "        self.utterance_ebd = SimpleAvgConvEBD(None, {}, avg_global=False)\n",
    "        # put the SimpleAvgConvEBD instance into the device (cpu or gpu), depending on the arguments\n",
    "        if self.args['cuda'] != -1: self.utterance_ebd.cuda(args['cuda'])\n",
    "\n",
    "        # put dimension as a class variable\n",
    "        self.dimension = dimension\n",
    "\n",
    "        # instanciate the LSTM class from PyTorch. Dimensions are divided by 2 due to bidirectional being True\n",
    "        self.lstm = nn.LSTM(input_size=300,\n",
    "                            hidden_size=dimension//2, \n",
    "                            num_layers=3,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        # instanciate a dropout layer with 0.5. This means, we will ignore (put to zeros) half (0.5) of the data to prevent the model from overfitting\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "\n",
    "        # instanciate a linear layer with an output size equal to the number of classes. This means this will be used to apply a criterion to compute the predictions.\n",
    "        self.hidden2tag = nn.Linear(dimension, num_class)\n",
    "\n",
    "    def forward(self, data, text_len=12):\n",
    "        '''\n",
    "        The forward function. Used to apply the model (during training or inference).\n",
    "        '''\n",
    "        # # use the function previously defined, in order to put the data values in the GPU is said so in the args\n",
    "        # data = batch_to_cuda(data, self.args['cuda'])\n",
    "        # # keep the device in a variable in order to prevent further mistakes\n",
    "        # device = data['text'].device\n",
    "\n",
    "        # use the utterance average embeddings to transform the data['text'] into a representation of conversation with a vector per utterance \n",
    "        text_emb = self.utterance_ebd(data['text'])\n",
    "\n",
    "        # apply the LSTM and retrieve the output, and the hidden vector. Hidden vector is not used afterwards. It would be useful in case of another type of LSTM for instance\n",
    "        output, hidden = self.lstm(text_emb)\n",
    "\n",
    "        # apply the dropout layer (ignore 50% of the data)\n",
    "        output = self.drop(output)\n",
    "\n",
    "        # apply the linear layer to have class logits\n",
    "        outputs = self.hidden2tag(output)\n",
    "\n",
    "        # keep some dimension infos as variable for convenience\n",
    "        batch_size = outputs.size(0)\n",
    "        seq_len = outputs.size(1)\n",
    "\n",
    "        # modify the outputs representation to prepare score computation\n",
    "        outputs = outputs.view(batch_size*seq_len, -1)\n",
    "        # apply a softmax on the outputs to obtain probabilities\n",
    "        scores = F.log_softmax(outputs, 1)\n",
    "\n",
    "        # get the predicted tags using the maximum probability from the softmax\n",
    "        _, tag_seq  = torch.max(scores, 1)\n",
    "        # reshape the predicted tags to follow the batch and sequence length\n",
    "        tag_seq = tag_seq.view(batch_size, seq_len)\n",
    "\n",
    "        # some example of manual class weights\n",
    "        # weights = torch.Tensor([0.1, 1, 1, 1, 1, 1, 1]).to(device)\n",
    "\n",
    "        \n",
    "        if 'class_weights' in self.args:\n",
    "          # class weights from args if there is any. It should be a torch tensor, but we move it to the dedicated device\n",
    "          # we use class weights to influence the Negative Log Likelihood. Influencing in the same time the backpropagation and, thus, the update of the model\n",
    "          loss_fn = nn.NLLLoss(weight=self.args['class_weights'].to(device))  \n",
    "        else: \n",
    "          # if not 'class_weights' key in the args dict(), we use the Negative Log Likelihood as is\n",
    "          loss_fn = nn.NLLLoss()\n",
    "\n",
    "        # apply the loss function (Softmax + NLLLoss = Cross Entropy)\n",
    "        loss = loss_fn(scores, data['label'].view(batch_size*seq_len))\n",
    "\n",
    "        # we return 3 elements as a tuple : the loss, the softmax outputs, and the predicted tag set already in a good format\n",
    "        return loss, scores, tag_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "89a7be42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, ep, args):\n",
    "  # set the model into a training mode : the model's weights and parameters WILL BE updated!\n",
    "  model.train()\n",
    "  # initialize empty lists for losses and accuracies\n",
    "  loss_it, acc_it = list(), list()\n",
    "\n",
    "  # start the loop over all the training batches. This means one full epoch.\n",
    "  for it, batch in tqdm(enumerate(train_loader), desc=\"Epoch %s:\" % (ep), total=train_loader.__len__()):\n",
    "    \n",
    "    # put parameters of the model and the optimizer to zero before doing another iteration\n",
    "    optimizer.zero_grad()\n",
    "    model.zero_grad()\n",
    "\n",
    "    # apply the model on the batch\n",
    "    loss, logits, tag_seq = model(batch)\n",
    "    # compute gradient values\n",
    "    loss.backward()\n",
    "    # indicate to the optimizer we've done a step\n",
    "    optimizer.step()\n",
    "    # append the value of the loss for the current iteration (it). .item() retrieve the nuclear value as a int/long\n",
    "    loss_it.append(loss.item())\n",
    "    \n",
    "    # Those 3 lines compute the accuracy and then append it the same way as the loss above\n",
    "    correct = (tag_seq.flatten() == batch['label'].flatten()).float().sum()\n",
    "    acc = correct / batch['label'].flatten().size(0)\n",
    "    acc_it.append(acc.item())\n",
    "\n",
    "  # simple averages of losses and accuracies for this epoch\n",
    "  loss_it_avg = sum(loss_it)/len(loss_it)\n",
    "  acc_it_avg = sum(acc_it)/len(acc_it)\n",
    "  \n",
    "  # print useful information about the training progress and scores on this training set's full pass (i.e. 1 epoch)\n",
    "  print(\"Epoch %s/%s : %s : (%s %s) (%s %s)\" % (colored(str(ep), 'blue'),args['max_eps'] , colored('Training', 'blue'), colored('loss', 'cyan'), sum(loss_it)/len(loss_it), colored('acc', 'cyan'), sum(acc_it) / len(acc_it)))\n",
    "\n",
    "def inference(target, loader, model):\n",
    "  \"\"\"\n",
    "    Args:\n",
    "      target (str): modify the display, usually either 'validation' or 'test'\n",
    "  \"\"\"\n",
    "  # set the model into a evaluation mode : the model's weights and parameters will NOT be updated!\n",
    "  model.eval()\n",
    "\n",
    "  # intialize empty list to populate later on\n",
    "  loss_it, acc_it, f1_it = list(), list(), list()\n",
    "  # preds = predicted values ; trues = true values .... obviously~\n",
    "  preds, trues = list(), list()\n",
    "\n",
    "  # loop over the loader batches\n",
    "  for it, batch in tqdm(enumerate(loader), desc=\"%s:\" % (target), total=loader.__len__()):\n",
    "    # set an environnement without any gradient. So the tensor gradients are not considered \n",
    "    # (saves a lot of computation and memory, this is one of the many things that makes predicting far less costly than training)\n",
    "    with torch.no_grad():\n",
    "      # apply the model\n",
    "      loss, logits, tag_seq = model(batch)\n",
    "      # no need to backward() and other training stuff. Directly store the loss in the list\n",
    "      loss_it.append(loss.item())\n",
    "      \n",
    "      # compute the accuracy and store it\n",
    "      correct = (tag_seq.flatten() == batch['label'].flatten()).float().sum()\n",
    "      acc = correct / batch['label'].flatten().size(0)\n",
    "      acc_it.append(acc.item())\n",
    "      \n",
    "      # extend the predictions and true labels lists so we can compare them later on\n",
    "      # note how we first ensure the tensor are on cpu (.cpu()), then we detach() the gradient from the tensor, before transforming it to a simple python list (.tolist())\n",
    "      preds.extend(tag_seq.cpu().detach().tolist())\n",
    "      trues.extend(batch['label'].cpu().detach().tolist())\n",
    "\n",
    "  # compute the average loss and accuracy accross the iterations (batches)\n",
    "  loss_it_avg = sum(loss_it)/len(loss_it)\n",
    "  acc_it_avg = sum(acc_it)/len(acc_it)\n",
    "  \n",
    "  # print useful information. Important during training as we want to know the performance over the validation set after each epoch\n",
    "  print(\"%s : (%s %s) (%s %s)\" % ( colored(target, 'blue'), colored('loss', 'cyan'), sum(loss_it)/len(loss_it), colored('acc', 'cyan'), sum(acc_it) / len(acc_it)))\n",
    "\n",
    "  # return the true and predicted values with the losses and accuracies\n",
    "  return trues, preds, loss_it_avg, acc_it_avg, loss_it, acc_it \n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "def run_epochs(model, args):\n",
    "\n",
    "  if args['cuda'] != -1:\n",
    "      model.cuda(args['cuda'])\n",
    "      device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "      args['device'] = device\n",
    "      print(\"device set to %s\" % (device) )\n",
    "\n",
    "  # we set the optimizer as Adam with the learning rate (lr) set in the arguments\n",
    "  # you can look at the different optimizer available here: https://pytorch.org/docs/stable/optim.html\n",
    "  optimizer = optim.Adam(model.parameters(), lr = args['lr'])\n",
    "\n",
    "  # define an empty list to store validation losses for each epoch\n",
    "  val_ep_losses = list()\n",
    "  # iterate over the number of max epochs set in the arguments\n",
    "  for ep in range(args['max_eps']):\n",
    "    # train the model using our defined function\n",
    "    train(model, optimizer, ep, args)\n",
    "    # apply the model for inference using our defined function\n",
    "    trues, preds, val_loss_it_avg, val_acc_it_avg, val_loss_it, val_acc_it = inference(\"validation\", val_loader, model)\n",
    "    # append the validation losses (good losses should normally go down)\n",
    "    val_ep_losses.append(val_loss_it_avg)\n",
    "\n",
    "  # return the list of epoch validation losses in order to use it later to create a plot\n",
    "  return val_ep_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "6a8b2744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08157c2a17b746e69a05a0ef9a8652bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0::   0%|          | 0/173 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch \u001b[34m0\u001b[0m/10 : \u001b[34mTraining\u001b[0m : (\u001b[36mloss\u001b[0m 0.9512702026808193) (\u001b[36macc\u001b[0m 0.6036849721749394)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "484d8438eee34c6296d6730b0157de2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation::   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mvalidation\u001b[0m : (\u001b[36mloss\u001b[0m 0.8433830857276916) (\u001b[36macc\u001b[0m 0.6019965410232544)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e96713c23b45acbe6d4bb18cade944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1::   0%|          | 0/173 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch \u001b[34m1\u001b[0m/10 : \u001b[34mTraining\u001b[0m : (\u001b[36mloss\u001b[0m 0.758544066737842) (\u001b[36macc\u001b[0m 0.6661699166187661)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea3dd1eba1c48c7890d14fa2c29ef2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation::   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mvalidation\u001b[0m : (\u001b[36mloss\u001b[0m 0.8120001276334127) (\u001b[36macc\u001b[0m 0.6251736124356587)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7269a38ed7a4a8a8244de1735f2607c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2::   0%|          | 0/173 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch \u001b[34m2\u001b[0m/10 : \u001b[34mTraining\u001b[0m : (\u001b[36mloss\u001b[0m 0.7278653090399814) (\u001b[36macc\u001b[0m 0.6849635715429494)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f29a17d1cc847ce8db98a0973914553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation::   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mvalidation\u001b[0m : (\u001b[36mloss\u001b[0m 0.74965527455012) (\u001b[36macc\u001b[0m 0.6875868082046509)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3166900086a34383b626e02160259fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3::   0%|          | 0/173 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch \u001b[34m3\u001b[0m/10 : \u001b[34mTraining\u001b[0m : (\u001b[36mloss\u001b[0m 0.5798608290322255) (\u001b[36macc\u001b[0m 0.7847347686745528)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66984f5c83c844169c4303ba041187b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation::   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mvalidation\u001b[0m : (\u001b[36mloss\u001b[0m 0.5835395733515422) (\u001b[36macc\u001b[0m 0.7589409669240316)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393e2f645be042a38c2a092ea20c4ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4::   0%|          | 0/173 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch \u001b[34m4\u001b[0m/10 : \u001b[34mTraining\u001b[0m : (\u001b[36mloss\u001b[0m 0.5089281425310698) (\u001b[36macc\u001b[0m 0.8124021543243717)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "021a182cc7334ae2bf6841135d69c195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation::   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mvalidation\u001b[0m : (\u001b[36mloss\u001b[0m 0.5573261777559916) (\u001b[36macc\u001b[0m 0.7677083333333333)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46a20b412524fc9a1fc8dcf5781adf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5::   0%|          | 0/173 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch \u001b[34m5\u001b[0m/10 : \u001b[34mTraining\u001b[0m : (\u001b[36mloss\u001b[0m 0.49175278851062576) (\u001b[36macc\u001b[0m 0.8164363565472509)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5794743333241fe8e21b3ec94dba0a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation::   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mvalidation\u001b[0m : (\u001b[36mloss\u001b[0m 0.5489070375760396) (\u001b[36macc\u001b[0m 0.7706597248713175)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31dba4571fc34f99bd24f8adb496003b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6::   0%|          | 0/173 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch \u001b[34m6\u001b[0m/10 : \u001b[34mTraining\u001b[0m : (\u001b[36mloss\u001b[0m 0.47866380421412474) (\u001b[36macc\u001b[0m 0.8193792156401397)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d981ebc7c645ae88c953a4db42301b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation::   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mvalidation\u001b[0m : (\u001b[36mloss\u001b[0m 0.52357919216156) (\u001b[36macc\u001b[0m 0.7787326455116272)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3238eb0613cb4fedad101e1890f7d772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7::   0%|          | 0/173 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch \u001b[34m7\u001b[0m/10 : \u001b[34mTraining\u001b[0m : (\u001b[36mloss\u001b[0m 0.46228270982042213) (\u001b[36macc\u001b[0m 0.8231575120391185)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f00091ced174b83a5c7fa066c687f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation::   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mvalidation\u001b[0m : (\u001b[36mloss\u001b[0m 0.489817080895106) (\u001b[36macc\u001b[0m 0.7928819457689921)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f2f006e7c754aa397733f488e307808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8::   0%|          | 0/173 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch \u001b[34m8\u001b[0m/10 : \u001b[34mTraining\u001b[0m : (\u001b[36mloss\u001b[0m 0.4451792135059489) (\u001b[36macc\u001b[0m 0.8298109349487834)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb9dd19ddd843aa933b1e0571999ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation::   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mvalidation\u001b[0m : (\u001b[36mloss\u001b[0m 0.47515952785809834) (\u001b[36macc\u001b[0m 0.8013020873069763)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f6231e80494e90b38ecce1847ed4a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9::   0%|          | 0/173 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch \u001b[34m9\u001b[0m/10 : \u001b[34mTraining\u001b[0m : (\u001b[36mloss\u001b[0m 0.4325725713561725) (\u001b[36macc\u001b[0m 0.8341913526457858)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7859eaaf00e47f28ebb5f3c2b048012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation::   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mvalidation\u001b[0m : (\u001b[36mloss\u001b[0m 0.47294171849886574) (\u001b[36macc\u001b[0m 0.8006076415379842)\n"
     ]
    }
   ],
   "source": [
    "args.update({'max_eps': 10, 'lr': 0.001, 'device': 'cpu', 'cuda': -1, 'seq_len':12, 'num_class': 5})\n",
    "\n",
    "# Instantiate model with pre-trained fasttext vectors\n",
    "# Here we set the dimension to 50 to make it faster and we only consider a small conversation length (12)\n",
    "model = BiLSTM(pretrained_vectors.vectors, args['num_class'], args, dimension=50, freeze_embeddings = True )\n",
    "loss_list_val = run_epochs(model, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "4bf1d9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(loss_list_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "dc15ccb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a559122df6641b5975720b72726e5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test::   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mtest\u001b[0m : (\u001b[36mloss\u001b[0m 0.4128587365150452) (\u001b[36macc\u001b[0m 0.8378472169240315)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      inform       0.70      0.95      0.80      3271\n",
      "    question       0.86      0.88      0.87      1985\n",
      "   directive       0.62      0.27      0.37      1176\n",
      "  commissive       0.65      0.12      0.20       681\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      7113\n",
      "   macro avg       0.71      0.55      0.56      7113\n",
      "weighted avg       0.72      0.74      0.69      7113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, RocCurveDisplay \n",
    "trues, preds, loss_it_avg, acc_it_avg, loss_it, acc_it = inference(\"test\", test_loader, model)\n",
    "names = ['__dummy__', 'inform', 'question', 'directive', 'commissive']\n",
    "names.remove('__dummy__') # dummy label is not interesting\n",
    "print(classification_report(np.array(trues).flatten(), np.array(preds).flatten(), target_names=names, labels=[1, 2, 3, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "17695e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.296875\n"
     ]
    }
   ],
   "source": [
    "total=0\n",
    "good=0\n",
    "for t, p in zip(trues, preds):\n",
    "    for i in range(len(trues)) :\n",
    "        if trues[i] != 0 :\n",
    "            total+=1\n",
    "            if trues[i]==preds[i] :\n",
    "                good+=1\n",
    "print(good/total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
